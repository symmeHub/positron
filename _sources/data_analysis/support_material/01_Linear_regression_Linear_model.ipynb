{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(dataM:support:LinReg)=\n",
    "# Linear regression - Linear model\n",
    "\n",
    "Linear regression is a fundamental technique in data science used to model the relationship between a dependent variable and one or more independent variables. \n",
    "It is widely used for predictive analysis, trend forecasting, and determining the strength of predictors. \n",
    "By fitting a linear equation to observed data, linear regression helps in understanding how the dependent variable changes with variations in the independent variables, making it a powerful tool for both explanatory and predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scope\n",
    "\n",
    "* A finite number $N$ of data points are available: find the best line going trought this $N$ points.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "![reg](https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import ipywidgets as ipw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction with a simple tow points line equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's annalyse how to determine the simple equation of a linear function ($y=ax+b$) kowing tow points of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the known points\n",
    "y = np.array([-1, 2])\n",
    "x = np.array([0.5, 3])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To dertermine the $a$ and $b$ coefficents, we have to solve the following system:\n",
    "\n",
    "$$\n",
    "y_0=ax_0+b\n",
    "$$\n",
    "$$\n",
    "y_1=ax_1+b\n",
    "$$\n",
    "\n",
    "\n",
    "Lets reorgenized a bit this system:\n",
    "\n",
    "$$b + ax_0 = y_0$$\n",
    "\n",
    "$$b + ax_1 = y_1$$\n",
    "\n",
    "Its now easy to write it as a linear system:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 & x_0 \\\\\n",
    "1 & x_1 \n",
    "\\end{bmatrix}\n",
    ".\n",
    "\\begin{bmatrix} \n",
    "b \\\\\n",
    "a\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "y_0 \\\\\n",
    "y_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Therfore the $a$ and $b$ coefficents can be determine by inversing the linear system:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "b \\\\\n",
    "a\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "1 & x_0 \\\\\n",
    "1 & x_1 \n",
    "\\end{bmatrix}^{-1}\n",
    ".\n",
    "\\begin{bmatrix} \n",
    "y_0 \\\\\n",
    "y_1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's do this with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# definition of the involved matrix :\n",
    "X = np.array([[1, x[0]], [1, x[1]]])\n",
    "print(\"X=\", X)\n",
    "Y = np.array([y[0], y[1]]).T\n",
    "print(\"Y=\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inversion of the systeme\n",
    "coef = np.dot(np.linalg.inv(X), Y)\n",
    "a = coef[1]\n",
    "b = coef[0]\n",
    "print(\n",
    "    \"a=\",\n",
    "    a,\n",
    ")\n",
    "print(\"b=\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw the obtained line\n",
    "N = 10\n",
    "xmin, xmax = 0.0, 4\n",
    "xi = np.linspace(xmin, xmax, N)\n",
    "yi = a * xi + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(xi, yi, \"r\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What append if we add a third point ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the known points\n",
    "y = np.array([-1, 2, 0])\n",
    "x = np.array([0.5, 3, 1.5])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To dertermine the $a$ and $b$ coefficents, we have to solve the following system:\n",
    "\n",
    "$$y_0=ax_0+b$$\n",
    "\n",
    "$$y_1=ax_1+b$$\n",
    "\n",
    "$$y_2=ax_2+b$$\n",
    "\n",
    "This system is over deffined: we have 2 unkowns ($a$,$b$) and 3 equations. \n",
    "\n",
    "The goal is now to find the $a$ and $b$ coefficients (i.e. to find the linear equation) that fit the best the given data.\n",
    "\n",
    "We can rewrite the equations in the form of the following linear system:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 & x_0 \\\\\n",
    "1 & x_1 \\\\\n",
    "1 & x_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "b \\\\\n",
    "a\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "y_0 \\\\\n",
    "y_1 \\\\\n",
    "y_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The system can be express in a genral form:\n",
    "\n",
    "$$X \\beta=Y$$\n",
    "\n",
    "The matrix $X$ is not square, and therfore not inversible. The methode presented above is no more apllicable.\n",
    "\n",
    "The trick is to multiply the system by the transposed of $X$.\n",
    "\n",
    "$$X^t X \\beta= X^t Y$$\n",
    "\n",
    "The therm $X^t X$ is now a square matrix. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's check this affirmation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construcion of the X matrix\n",
    "X = np.array([np.ones(x.size), x]).T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computation of Xt X\n",
    "np.dot(X.T, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained matrix is a square matrix and it can proved that this matrix is symmetric, and therfore always inversible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous equation:\n",
    "$$X^t X \\beta= X^t Y$$\n",
    "\n",
    "The $\\beta$ vector can be express by as :\n",
    "\n",
    "$$\\beta= \\left( X^t X \\right)^{-1} X^t Y$$\n",
    "\n",
    "This operator is the least square estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's do this with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construcion of the X matrix\n",
    "X = np.array([np.ones(x.size), x]).T\n",
    "\n",
    "# Construcion of the Y matrix\n",
    "Y = y.T\n",
    "\n",
    "print(\"X=\", X)\n",
    "\n",
    "print(\"Y=\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computation of the least square estimator\n",
    "beta = np.dot(np.linalg.inv(np.dot(X.T, X)), np.dot(X.T, Y))\n",
    "print(\"beta=\", beta)\n",
    "\n",
    "print(\"The fitted linear function is:\")\n",
    "print(\"y=\", beta[1], \"x +\", beta[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now its time to plot the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw the obtained line\n",
    "N = 10\n",
    "xmin, xmax = 0.0, 4\n",
    "xi = np.linspace(xmin, xmax, N)\n",
    "yi = beta[0] + beta[1] * xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(xi, yi, \"r\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## With a larger data set ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The data set : a synthetique data set with some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "xmin, xmax = 0.0, 4\n",
    "x = np.linspace(xmin, xmax, N) + np.random.rand(N)\n",
    "y = (3.3 * x - 2) + 2 * np.random.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"o\", label=\"Data\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Determination of the coefficent by regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construcion of the X matrix\n",
    "X = np.array([np.ones(x.size), x]).T\n",
    "\n",
    "# Construcion of the Y matrix\n",
    "Y = y.T\n",
    "\n",
    "# Computation of the least square estimator\n",
    "beta = np.dot(np.linalg.inv(np.dot(X.T, X)), np.dot(X.T, Y))\n",
    "\n",
    "print(\"The fitted linear function is:\")\n",
    "print(\"y=\", beta[1], \"x +\", beta[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Draw the obtain regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "xmin, xmax = 0.0, 5\n",
    "xi = np.linspace(xmin, xmax, N)\n",
    "yi = beta[0] + beta[1] * xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"o\", label=\"Data\")\n",
    "plt.plot(xi, yi, \"r\", label=\"Regression\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Does python  know how to do that in one line ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Of course yes ! \n",
    "\n",
    "### Using the polyfit function of numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the coefficient using the least square methode\n",
    "beta = np.polyfit(x, y, 1)\n",
    "print(\"beta=\", beta)\n",
    "\n",
    "# creat the associate 1d polynomila function\n",
    "fit = np.poly1d(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Draw the obtaine regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "xmin, xmax = 0.0, 5\n",
    "xi = np.linspace(xmin, xmax, N)\n",
    "yi_numpy = fit(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"o\", label=\"Data\")\n",
    "plt.plot(xi, yi, \"+r\", label=\"Regression\")\n",
    "plt.plot(xi, yi_numpy, \"g\", label=\"Regression Numpy\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using numpy linalg function: \n",
    "\n",
    "For this methode de $X$ ans $Y$ matrix must be given by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta, r, rank, s = np.linalg.lstsq(X, Y, rcond=None)\n",
    "print(\"beta=\", beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky us, all methodes give the same results !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the effect of noise on the resulting regression ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "xmin, xmax = 0.0, 4\n",
    "\n",
    "\n",
    "def get_data(N, sigma):\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    y = (3.3 * x - 2) + sigma * np.random.randn(N)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def compute_reg(x, y):\n",
    "    beta, residuals, rank, singular_values, rcond = np.polyfit(x, y, 1, full=True)\n",
    "    fit = np.poly1d(beta)\n",
    "    SStot = ((y - y.mean()) ** 2).sum()\n",
    "    SSres = residuals[0]\n",
    "    R2 = 1 - SSres / SStot\n",
    "    return beta, fit([xmin, xmax]), R2\n",
    "\n",
    "\n",
    "x, y = get_data(100, 0.0)\n",
    "beta, fity, R2 = compute_reg(x, y)\n",
    "fig = plt.figure()\n",
    "(points_plot,) = plt.plot(x, y, \"o\", label=\"Data\")\n",
    "(line,) = plt.plot([xmin, xmax], fity, \"-r\", label=\"Regression\")\n",
    "plt.plot([xmin, xmax], fity, \"-g\", label=\"Non Noisy data\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "@ipw.interact(N=(5, 100, 10), sigma=(0.0, 2.0, 0.1))\n",
    "def update(N, sigma):\n",
    "    x, y = get_data(N, sigma)\n",
    "    beta, fity, R2 = compute_reg(x, y)\n",
    "    points_plot.set_xdata(x)\n",
    "    points_plot.set_ydata(y)\n",
    "    line.set_ydata(fity)\n",
    "    plt.title(\"$R^2$={:0.2f}\".format(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{admonition} Note \n",
    ":class: tip \n",
    "To go further the reader can read the [](dataM:support:LinRegAdvanced) notebook.\n",
    "\n",
    "::::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "livereveal": {
   "footer": "<h3>Polytech Annecy / Chambery</h3>",
   "scroll": true,
   "theme": "sky",
   "transition": "zoom"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
